{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scope of this personal project was to:\n",
    "\n",
    "* Go deep with computer vision and neural nets\n",
    "* Learn modern neural nets framework (tensorflow, given Google's bet on it)\n",
    "* Find some pretty cool application to have a test case\n",
    "* Give it a spin in the GCP environment, the \"AI platform\" and understand Google's offering for Machine Learning\n",
    "\n",
    "On the range of applications, I wanted something different from what I have been doing recently: I've been very business oriented, mainly working on predictions on structured datasets focusing on the banking industry (churn, scoring, marketing). Here, I wanted to focus on something different, finding some fun application as an excuse to check the goals above.\n",
    "\n",
    "How about going back to my artsy days? Among many hobbys I've had throughout my days, photography was on my top list for about a year. It was a great excuse to travel around on my own and to focus on self-learning on a topic far away from my research and job. Googling a little bit, I found a fantastic idea for a project: how would any given picture look, if it had been drawn in the style of any particular famous painter (say Picasso or Van Gogh)? How would my own photos look if they had been painted directly by one of the greatest? Then something came up: how would the photos I took from my own little niece (she's 6!) look if they would've been drawn by...HERSELF? I was sold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural style transfer and convolutional neural nets\n",
    "\n",
    "The technique doing this is called \"Neural Style Transfer\". The paper by [Gatys et al. (2015)](https://https://arxiv.org/abs/1508.06576) implemented it first, and there are some good , understandable implementations:\n",
    "\n",
    "* Harish Narayanan, [Convolutional neural networks for artistic style transfer.](https://harishnarayanan.org/writing/artistic-style-transfer/)\n",
    "* Log0, [TensorFlow Implementation of \"A Neural Algorithm of Artistic Style\".](http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style)\n",
    "\n",
    "In summary, this technique takes two images as inputs: one for the content of the final output, the other for the style. The output is a mixture of the two, \"painting\" the objects or scenery given by the former (content) image, but in the style of the latter (style image). Some very intriguing art can be created this way.\n",
    "\n",
    "To get a step by step implementation, I searched for learning materials. I found the [Coursera, deeplearning.ai specialization](https://www.coursera.org/specializations/deep-learning) to be a fantastic resource, not just for this technique, but for deep learning in general (I needed some brush up). It starts with step by step implementations of shallow neural nets (yep...directly in numpy), and it builds up to more advanced models. In the 4th course on convolutional nets, one of the exercises is to code your own implementation of the style transfer algorithm. I completed about half the material for this project in a couple of weeks (material worth around two months' work, so it was *intense*). It was quite challenging at first but very satisfactory. So definitely, next personal project is to complete the other courses of the specialization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without getting into the details (have a look at the references above, or the notebook on **REPO**), what I found most interesting is that the algorithm doesn't update any weights, but the pixels of the image themselves. The key, fundamental insight, was to define a cost function that minimizes the distance between content and style. I found it amazing to be able to define \"style\" of a piece of art in a concrete mathematical way (I know, might by trivial nowdays for those in the field, but I'm still amazed by these kinda things).\n",
    "\n",
    "The second thing that's important, is the \"transfer learning\" part. A traditional neural net starts learning simple features in the shallow layers, such as identifying vertical lines or particular shades of colours, and by moving into deeper layers, it combines them to start creating more complex features (such as noses, ears, and finally faces, for example). Training such networks from scratch can be expensive, so transfer learning implies taking some of the parameters learned in the feature extraction layers of some benchmark network, and using them as they are. This allows the new model to detect features in the images right off-the-bat, and using them to extract more complex signals such as style. By the way, I found [this explanation](https://www.youtube.com/watch?v=MQm6ZP1F6ms) of feature extraction via convolution operations and cross-correlation very interesting, and its association with signal theory quite clear.\n",
    "\n",
    "By the way, transfer learning for this algorithm uses the model by [Karen Simonyan and Andrew Zisserman (2015)](https://arxiv.org/pdf/1409.1556.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation files\n",
    "\n",
    "The repo has two implementations of the code:\n",
    "* NAME: all files from the implementation I completed based on the deeplearning.ai specialization exercises. Not only having the programming assingments is a great future reference, but it has *great* explanations and intuitions about the algorithm in the notebook. A true gem! Notice however, that this version was meant for Tensorflow 1.4. Given version availabilities in the tools used in GCP (see below), this implementation couldn't run properly on Google's Virtual Machines deployed via the \"Notebooks\" products (in beta at the moment). Hence, had to look for a different implementation based on Tensorflow 2.0.\n",
    "\n",
    "* NAME: * [](https://www.tensorflow.org/tutorials/generative/style_transfer) Tensorflow.or\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCP\n",
    "\n",
    "*\n",
    "\n",
    "The reason is related to running previous implementations on GCP (more below). The following outputs were obtained with the **FILE**\n",
    "\n",
    "SHOW MONET AND NORMALS, MONKEYS AND ANTONIA!\n",
    "\n",
    "After finishing my implementation of the transfer learning algorithm, I wanted to take it one step further. This was the perfect excuse to have a look at the most recent products of Google, in particular the AI platform and its offerings for connecting with toher cloud services, in particular storage (Google Cloud Storage) and deployment (AI predictions).\n",
    "\n",
    "Google offers tools for an end-to-end machine learning systems. [This book from O'Reilly](http://shop.oreilly.com/product/0636920057628.do) is a great reference for building complete pipelines from ingestion to deployment (and great for good data science practice in general). However, recently Google (and many other vendors) have been switching aways from deploying Hadoop clusters (Dataproc in Google's case), to offering simpler machines \n",
    "\n",
    "Notebooks is new quick development (VM instances easy to deploy).\n",
    "Pricing is reasonable\n",
    "Connection to everything (storage, AI prediction, through notebook interface)\n",
    "\n",
    "Found serveral problems. Mostly quality of life, so quite annoying but not deal breaker. These were mainly with the Notebooks service:\n",
    "\n",
    "* Couldn't integrate with GITHub, althought is supposed to\n",
    "* For several days, deploying VMs (notebooks) with Tensorflow 2.0 generated errors\n",
    "* Saving was very inconsistent. Lost work many times because had to restart the VM (restarting the kernel alone wouldn't fix it)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Tried versions:\n",
    "* No 2.0 initially\n",
    "* Old versions have bugs:\n",
    "    * Nan total cost\n",
    "    * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos:\n",
    "* Setup github with main parts:\n",
    "    * One for coursera code\n",
    "    * One for GCP and 2.0 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
