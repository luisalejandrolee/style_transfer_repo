{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scope of this personal project was to:\n",
    "\n",
    "* Go deep with computer vision and neural nets\n",
    "* Learn modern neural nets framework (tensorflow, given Google's bet on it)\n",
    "* Find some pretty cool application to have a test case\n",
    "* Give it a spin in the GCP environment, the \"AI platform\" and understand Google's offering for Machine Learning\n",
    "\n",
    "On the range of applications, I wanted something different from what I have been doing recently: I've been very business oriented, mainly working on predictions on structured datasets focusing on the banking industry (churn, scoring, marketing). Here, I wanted to focus on something different, finding some fun application as an excuse to check the goals above.\n",
    "\n",
    "How about going back to my artsy days? Among many hobbys I've had throughout my days, photography was on my top list for about a year. It was a great excuse to travel around on my own and to focus on self-learning on a topic far away from my research and job. Googling a little bit, I found a fantastic idea for a project: how would any given picture look, if it had been drawn in the style of any particular famous painter (say Picasso or Van Gogh)? How would my own photos look if they had been painted directly by one of the greatest? Then something came up: how would the photos I took from my own little niece (she's 6!) look if they would've been drawn by...HERSELF? I was sold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural style transfer and convolutional neural nets\n",
    "\n",
    "The technique doing this is called \"Neural Style Transfer\". The paper by [Gatys et al. (2015)](https://https://arxiv.org/abs/1508.06576) implemented it first, and there are some good , understandable implementations:\n",
    "\n",
    "* Harish Narayanan, [Convolutional neural networks for artistic style transfer.](https://harishnarayanan.org/writing/artistic-style-transfer/)\n",
    "* Log0, [TensorFlow Implementation of \"A Neural Algorithm of Artistic Style\".](http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style)\n",
    "\n",
    "In summary, this technique takes two images as inputs: one for the content of the final output, the other for the style. The output is a mixture of the two, \"painting\" the objects or scenery given by the former (content) image, but in the style of the latter (style image). Some very intriguing art can be created this way.\n",
    "\n",
    "To get a step by step implementation, I searched for learning materials. I found the [Coursera, deeplearning.ai specialization](https://www.coursera.org/specializations/deep-learning) to be a fantastic resource, not just for this technique, but for deep learning in general (I needed some brush up). It starts with step by step implementations of shallow neural nets (yep...directly in numpy), and it builds up to more advanced models. In the 4th course on convolutional nets, one of the exercises is to code your own implementation of the style transfer algorithm. I completed about half the material for this project in a couple of weeks (material worth around two months' work, so it was *intense*). It was quite challenging at first but very satisfactory. So definitely, next personal project is to complete the other courses of the specialization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without getting into the details (have a look at the references above, or the notebook on my second implementation mentioned below), what I found most interesting is that the algorithm doesn't update any weights, but the pixels of the image themselves. The key, fundamental insight, was to define a cost function that minimizes the distance between content and style. I found it amazing to be able to define \"style\" of a piece of art in a concrete mathematical way (I know, might by trivial nowdays for those in the field, but I'm still amazed by these kinda things).\n",
    "\n",
    "The second thing that's important, is the \"transfer learning\" part. A traditional neural net starts learning simple features in the shallow layers, such as identifying vertical lines or particular shades of colours, and by moving into deeper layers, it combines them to start creating more complex features (such as noses, ears, and finally faces, for example). Training such networks from scratch can be expensive, so transfer learning implies taking some of the parameters learned in the feature extraction layers of some benchmark network, and using them as they are. This allows the new model to detect features in the images right off-the-bat, and using them to extract more complex signals such as style. By the way, I found [this explanation](https://www.youtube.com/watch?v=MQm6ZP1F6ms) of feature extraction via convolution operations and cross-correlation very interesting, and its association with signal theory quite clear.\n",
    "\n",
    "Transfer learning for this algorithm uses the model by [Karen Simonyan and Andrew Zisserman (2015)](https://arxiv.org/pdf/1409.1556.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation files\n",
    "\n",
    "Important repo files. It has two implementations of the style transfer algorithm:\n",
    "\n",
    "## Tensorflow 2.0 implementation\n",
    "\n",
    "* Notebook \"final_style_transfer\": Based on [Tensorflow.org implementation](https://www.tensorflow.org/tutorials/generative/style_transfer). The file here is meant only to show the outputs, but the link to the original notebook has guidance and intuition. My code adds the necessary bundling to set the code as a module and package it for GCP deployment, as well as some conveniences functions to show and save the outputs. ___This notebook has the output results of different styles and my won photos! DO CHECK THEM___. With more time I should probably make the notebook more user friendly, but for that shall be left for a follow up with more time. For now, rejoice with outputs using my own monkey pictures taken from my trip to the Amazon, and some using my niece's own painting!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeplearning implementation\n",
    "\n",
    "* Folder \"deeplearning_implementation\": two files from the implementation I completed based on the deeplearning.ai specialization exercises. A full notebook with code and all intuitions and mathematical definitions, and a utils file used for referencing other functions needed. Not only having the programming assingments is a great future reference, but it has *great* explanations and intuitions about the algorithm in the notebook. A true gem! Notice however, that this version was meant for Tensorflow 1.4. Given version availabilities in the tools used in GCP (see below), this implementation couldn't run properly on Google's Virtual Machines deployed via the \"Notebooks\" products (in beta at the moment). Hence, had to look for the first, different implementation based on Tensorflow 2.0 (see above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Cloud Platform\n",
    "\n",
    "After finishing my implementation of the transfer learning algorithm, I wanted to take it one step further. This was the perfect excuse to have a look at the most recent Google's products, in particular the AI platform and its offerings for connecting with other cloud services, in particular storage (Google Cloud Storage) and deployment (AI predictions).\n",
    "\n",
    "Google offers tools for an end-to-end machine learning systems. [This book from O'Reilly](http://shop.oreilly.com/product/0636920057628.do) is a great reference for building complete pipelines from ingestion to deployment (and great for good data science practice in general). However, recently Google (and many other vendors) have been switching aways from deploying Hadoop clusters (Dataproc in Google's case), offering simpler ways to deploy VMs for auto scaling in production, without worrying about nodes or cluster setup.\n",
    "\n",
    "Particularly, \"Notebooks\" is Google's product for VMs preinstalled with all basic tool for data scientists (python, R, tensorflow, pandas, etc.) using a simple deployment UI as well as a Jupyter Lab interface. The main advantage is that it offers direct connection to all other main products (storage buckets, AI predictions, BigQuery, etc.)\n",
    "\n",
    "However, given that it was in beta mode at the moment, I found some annoying problems worth mentioning:\n",
    "\n",
    "* Couldn't integrate with GITHub, althought is supposed to. At the beggining thought it was not an issue, but then I had to do A LOT of updates to local machines, annoying installations (I'm looking at you gsutil SDK) and others just to download to local and upload to github.\n",
    "* For several days, deploying VMs (notebooks) with Tensorflow 2.0 generated errors and was not possible. Wasted loads of time deploying 1.4 Tensorflow environments, realizing the code didn't work (deeplearning.ai implementation) and suffering trying to update code.\n",
    "* Saving was VERY inconsistent. Lost work many times because had to restart the VM (restarting the kernel alone wouldn't fix it). After a while, saving error popups just made working unviable.\n",
    "\n",
    "Being in Beta state, all of this is understandable. Although quite annoying, all of this probably will be fixed at first official stable version. Overall, this was a great opportunity to test all the GCP tools and (almost) finishing the end to end deployment in the AI suite. The only missing part was that at the very end, realized that the AI prediction service (used to upload your application and expose your app as a service) doesn't support a Tensorflow 2.0 runtime at the moment. What a bummer! I spent a lot of time getting the details of the code and managed to upload the app, but of having an environment of an older tensorflow errors, couldn't be properly deployed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final thoughts\n",
    "\n",
    "This was a very intense and challenging project. Managed to complete several modules and courses of the deeplearning specialization, building from total scratch many neural nets for image classification tasks (cats vs. dogs, identifying hand signals for numbers, among others). I did this for my own learning interest, and as stepping stones to implement the neural style transfer algorithm. I enjoyed pretty much the outputs of my own personal photos!\n",
    "\n",
    "I also managed to test the whole GCP suite for machine learning. This engineering part is vital for the machine learning practicioner, and staying up to date on the tools and latest deployment services can be very useful when thinking about new products and pipelines.\n",
    "\n",
    "Finally, two things left to do when I get more time. First, I should probably wrap up all the codes and make all of this more userfriendly and tutorial focused, in order to get it out there in a blog. For now, the code is not that commented, and the process for deploying not recorded step by step (the main application code is there, and some support files will remind me about the main gsutil commands).\n",
    "\n",
    "Second, I'm eagerly waiting for the AI prediction service to allow a Tensorflow 2.0 runtime environment in order to complete the deployment. It was a bummer completing the code, exporting the packages, getting the permissions and all that jazz, to realizing at last minute it wasn't available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
